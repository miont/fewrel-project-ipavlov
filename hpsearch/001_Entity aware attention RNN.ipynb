{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.abspath(''), os.path.pardir))\n",
    "import numpy as np\n",
    "import torch\n",
    "from utils.data_loader import JSONFileDataLoader\n",
    "from utils.token_embedders.glove_json_embedder import GloveJsonEmbedder\n",
    "from utils.token_embedders.glove_embedder import GloveEmbedder\n",
    "from utils.token_embedders.elmo_embedder import ElmoEmbedder\n",
    "from utils.token_embedders.fasttext_embedder import FasttextEmbedder\n",
    "from framework import FewShotREFramework\n",
    "from models.sentence_encoders.cnn.sentence_encoder import CNNSentenceEncoder\n",
    "from models.sentence_encoders.inception_cnn.sentence_encoder import InceptionCNNSentenceEncoder\n",
    "from models.sentence_encoders.entity_aware_attention_rnn.sentence_encoder import EntityAwareAttentionRnn\n",
    "from models.fewshot.proto import Proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-way-5-shot Few-Shot Relation Classification\n",
      "Model: proto\n",
      "Loading data file...\n",
      "Finish loading\n",
      "Eliminating case sensitive problem...\n",
      "Finish eliminating\n",
      "Pre-processing data...\n",
      "Finish pre-processing\n",
      "Storing processed files...\n",
      "Finish storing\n",
      "Loading data file...\n",
      "Finish loading\n",
      "Eliminating case sensitive problem...\n",
      "Finish eliminating\n",
      "Pre-processing data...\n",
      "Finish pre-processing\n",
      "Storing processed files...\n",
      "Finish storing\n",
      "Loading data file...\n",
      "Finish loading\n",
      "Eliminating case sensitive problem...\n",
      "Finish eliminating\n",
      "Pre-processing data...\n",
      "Finish pre-processing\n",
      "Storing processed files...\n",
      "Finish storing\n",
      "Init GloVe embedder\n",
      "400000 vectors with dim 100\n"
     ]
    }
   ],
   "source": [
    "cuda = True\n",
    "\n",
    "model_name = 'proto'\n",
    "N = 5\n",
    "K = 5\n",
    "# if len(sys.argv) > 1:\n",
    "#     model_name = sys.argv[1]\n",
    "# if len(sys.argv) > 2:\n",
    "#     N = int(sys.argv[2])\n",
    "# if len(sys.argv) > 3:\n",
    "#     K = int(sys.argv[3])\n",
    "\n",
    "print(\"{}-way-{}-shot Few-Shot Relation Classification\".format(N, K))\n",
    "print(\"Model: {}\".format(model_name))\n",
    "\n",
    "max_length = 40\n",
    "data_path = os.path.join(os.path.abspath(''), os.path.pardir, 'data')\n",
    "train_data_loader = JSONFileDataLoader(os.path.join(data_path, 'train.json'), max_length=max_length, cuda=cuda)\n",
    "val_data_loader = JSONFileDataLoader(os.path.join(data_path, 'val.json'), max_length=max_length, cuda=cuda)\n",
    "test_data_loader = JSONFileDataLoader(os.path.join(data_path, 'test.json'), max_length=max_length, cuda=cuda)\n",
    "\n",
    "# word_embedder = GloveJsonEmbedder(word_vec_file_name='./data/glove/glove.6B.50d.json')\n",
    "# word_embedder = ElmoEmbedder(cuda=True, cuda_out=cuda)\n",
    "# word_embedder = FasttextEmbedder(cuda=cuda)\n",
    "word_vec_dim = 100\n",
    "word_embedder = GloveEmbedder(vec_dim=word_vec_dim, cuda=cuda, \n",
    "                              vectors_path=os.path.join(data_path, 'glove/glove.6B.{}d.txt').format(word_vec_dim))\n",
    "\n",
    "framework = FewShotREFramework(train_data_loader, val_data_loader, test_data_loader)\n",
    "# sentence_encoder = CNNSentenceEncoder(word_embedder, max_length, hidden_size=230)\n",
    "# sentence_encoder = InceptionCNNSentenceEncoder(word_embedder, max_length, pos_embedding_dim=3, sizes=[{3: 230}])\n",
    "# sentence_encoder = InceptionCNNSentenceEncoder(word_embedder, max_length, sizes=[{3: 200, 5:200, 7:200}, {3: 300, 5:300, 7:300}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_single_param(encoder_model_class:type, fewshot_model_class:type, framework:FewShotREFramework,\n",
    "                          param_name:str, param_values:list, other_params:dict, N=5, K=5):\n",
    "    print('Optimizing {} with possible values: {}'.format(param_name, param_values))\n",
    "    scores = []\n",
    "    for i, v in enumerate(param_values):\n",
    "        print('Iteration {}: {} = {}'.format(i+1, param_name, v))\n",
    "        sentence_encoder = encoder_model_class(**{param_name:v}, **other_params)\n",
    "        model = fewshot_model_class(sentence_encoder, hidden_size=sentence_encoder.hidden_size)\n",
    "        score = framework.train(model, 'tmp', 4, 20, N, K, 5, cuda=cuda, learning_rate=1, train_iter=2000)\n",
    "        scores.append(score)\n",
    "        print('Score: {:.4f}'.format(score))\n",
    "        print('-'*20)\n",
    "    best_val = param_values[np.argmax(scores)]\n",
    "    return scores, best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'word_embedder': word_embedder, \n",
    "    'max_length': max_length, \n",
    "    'hidden_size': 100, \n",
    "    'pos_embedding_dim': 50, \n",
    "    'n_heads': 4,\n",
    "    'attention_dim': 50,\n",
    "    'num_latent_types': 3,\n",
    "    'cuda': cuda,\n",
    "    'dropout_we': 0, \n",
    "    'dropout_rnn': 0, \n",
    "    'dropout_eaa': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_param = 'num_latent_types'\n",
    "del params[optimized_param]\n",
    "# values = [1, 3, 5, 7, 10, 15, 20, 30, 40, 50]\n",
    "values = [1, 3, 5, 10, 20, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word_embedder': GloveEmbedder(),\n",
       " 'max_length': 40,\n",
       " 'hidden_size': 100,\n",
       " 'pos_embedding_dim': 50,\n",
       " 'n_heads': 4,\n",
       " 'attention_dim': 50,\n",
       " 'cuda': True,\n",
       " 'dropout_we': 0,\n",
       " 'dropout_rnn': 0,\n",
       " 'dropout_eaa': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select number of entity latent types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter num_latent_types optimization\n",
      "Optimizing num_latent_types with possible values: [1, 3, 5, 10, 20, 30]\n",
      "Iteration 1: num_latent_types = 1\n",
      "Start training...\n",
      "step:    1 | loss: 2.980166, accuracy: 7.75%\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clement/Courses/Other/Deep_NLP/spring-2019/work/project/code/fewrel-project-ipavlov/env/lib/python3.6/site-packages/torch/nn/functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2000 | loss: 0.778004, accuracy: 74.79%\n",
      "[EVAL] step: 1000 | accuracy: 85.05%\n",
      "Best checkpoint\n",
      "\n",
      "####################\n",
      "\n",
      "Finish training tmp\n",
      "\n",
      "Successfully loaded checkpoint './checkpoint/tmp.pth.tar'\n",
      "[EVAL] step: 3000 | accuracy: 84.88%\n",
      "Test accuracy: 0.8488033129970233\n",
      "Score: 0.8488\n",
      "--------------------\n",
      "Iteration 2: num_latent_types = 3\n",
      "Start training...\n",
      "step: 2000 | loss: 0.785432, accuracy: 74.58%\n",
      "[EVAL] step: 1000 | accuracy: 85.28%\n",
      "Best checkpoint\n",
      "\n",
      "####################\n",
      "\n",
      "Finish training tmp\n",
      "\n",
      "Successfully loaded checkpoint './checkpoint/tmp.pth.tar'\n",
      "[EVAL] step: 3000 | accuracy: 85.12%\n",
      "Test accuracy: 0.8511833134293556\n",
      "Score: 0.8512\n",
      "--------------------\n",
      "Iteration 3: num_latent_types = 5\n",
      "Start training...\n",
      "step: 2000 | loss: 0.785122, accuracy: 74.57%\n",
      "[EVAL] step: 1000 | accuracy: 85.60%\n",
      "Best checkpoint\n",
      "\n",
      "####################\n",
      "\n",
      "Finish training tmp\n",
      "\n",
      "Successfully loaded checkpoint './checkpoint/tmp.pth.tar'\n",
      "[EVAL] step: 3000 | accuracy: 85.31%\n",
      "Test accuracy: 0.8530866470734279\n",
      "Score: 0.8531\n",
      "--------------------\n",
      "Iteration 4: num_latent_types = 10\n",
      "Start training...\n",
      "step: 2000 | loss: 0.792641, accuracy: 74.30%\n",
      "[EVAL] step: 1000 | accuracy: 84.01%\n",
      "Best checkpoint\n",
      "\n",
      "####################\n",
      "\n",
      "Finish training tmp\n",
      "\n",
      "Successfully loaded checkpoint './checkpoint/tmp.pth.tar'\n",
      "[EVAL] step: 3000 | accuracy: 84.23%\n",
      "Test accuracy: 0.8422666457692782\n",
      "Score: 0.8423\n",
      "--------------------\n",
      "Iteration 5: num_latent_types = 20\n",
      "Start training...\n",
      "step: 2000 | loss: 0.795867, accuracy: 74.21%\n",
      "[EVAL] step: 1000 | accuracy: 85.32%\n",
      "Best checkpoint\n",
      "\n",
      "####################\n",
      "\n",
      "Finish training tmp\n",
      "\n",
      "Successfully loaded checkpoint './checkpoint/tmp.pth.tar'\n",
      "[EVAL] step: 3000 | accuracy: 85.33%\n",
      "Test accuracy: 0.8533333136240642\n",
      "Score: 0.8533\n",
      "--------------------\n",
      "Iteration 6: num_latent_types = 30\n",
      "Start training...\n",
      "step:  759 | loss: 1.012971, accuracy: 67.50%\r"
     ]
    }
   ],
   "source": [
    "print('Parameter {} optimization'.format(optimized_param))\n",
    "scores, best_val = hyperopt_single_param(encoder_model_class=EntityAwareAttentionRnn, \n",
    "                          fewshot_model_class=Proto,\n",
    "                          framework=framework,\n",
    "                          param_name=optimized_param,\n",
    "                          param_values=values,\n",
    "                          other_params=params,\n",
    "                          N=5, K=5)\n",
    "print('Optimal value {} with score {}'.format(best_val, np.max(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt.plot(values, scores)\n",
    "plt.xlabel('value')\n",
    "plt.ylabel('score')\n",
    "plt.grid()\n",
    "plt.title('Parameter \"{}\" optimization'.format(optimized_param))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
